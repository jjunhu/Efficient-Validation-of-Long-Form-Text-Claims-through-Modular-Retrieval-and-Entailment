{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DPRQuestionEncoder, DPRContextEncoder, DPRQuestionEncoderTokenizer, DPRContextEncoderTokenizer, AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from rank_bm25 import BM25Okapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "import torch\n",
    "\n",
    "# Base class for retrieval\n",
    "class Retriever:\n",
    "    def retrieve_passages(self, book_text, claim):\n",
    "        raise NotImplementedError(\"Subclasses must implement this method.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPR-based Retriever\n",
    "class DPRRetriever(Retriever):\n",
    "    def __init__(self):\n",
    "        self.question_encoder = DPRQuestionEncoder.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "        self.question_encoder_tokenizer = DPRQuestionEncoderTokenizer.from_pretrained(\"facebook/dpr-question_encoder-single-nq-base\")\n",
    "        self.context_encoder = DPRContextEncoder.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "        self.context_encoder_tokenizer = DPRContextEncoderTokenizer.from_pretrained(\"facebook/dpr-ctx_encoder-single-nq-base\")\n",
    "\n",
    "    def retrieve_passages(self, book_text, claim, top_k=5):\n",
    "        question_input = self.question_encoder_tokenizer(claim, return_tensors='pt')\n",
    "        context_input = self.context_encoder_tokenizer(book_text, truncation=True, padding=True, return_tensors='pt', max_length=512)\n",
    "        question_emb = self.question_encoder(**question_input).pooler_output\n",
    "        context_emb = self.context_encoder(**context_input).pooler_output\n",
    "        cos = torch.nn.CosineSimilarity(dim=1)\n",
    "        similarities = cos(question_emb, context_emb)\n",
    "        top_k_indices = similarities.topk(k=top_k).indices\n",
    "        return [book_text[idx] for idx in top_k_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25-based Retriever\n",
    "class BM25Retriever(Retriever):\n",
    "    def __init__(self):\n",
    "        self.tokenizer = word_tokenize\n",
    "\n",
    "    def retrieve_passages(self, book_text, claim, top_k=5):\n",
    "        tokenized_corpus = [self.tokenizer(doc) for doc in book_text]\n",
    "        bm25 = BM25Okapi(tokenized_corpus)\n",
    "        tokenized_claim = self.tokenizer(claim)\n",
    "        doc_scores = bm25.get_scores(tokenized_claim)\n",
    "        top_k_indices = sorted(range(len(doc_scores)), key=lambda i: doc_scores[i], reverse=True)[:top_k]\n",
    "        return [book_text[idx] for idx in top_k_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entailment checking function using T5\n",
    "class EntailmentChecker:\n",
    "    def __init__(self):\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "\n",
    "    def check_entailment(self, claim, passages):\n",
    "        results = []\n",
    "        for passage in passages:\n",
    "            input_text = f\"claim: {claim} context: {passage}\"\n",
    "            input_ids = self.tokenizer(input_text, return_tensors='pt').input_ids\n",
    "            outputs = self.model.generate(input_ids)\n",
    "            result = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            results.append(result)\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Another piece of text from the book', 'a claim from the book']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "book_text = [\"\", \"\"]  # This should be a list of passages\n",
    "claim = \".\"\n",
    "\n",
    "# Choose the retriever\n",
    "retriever = BM25Retriever() \n",
    "\n",
    "# Retrieve passages\n",
    "retrieved_passages = retriever.retrieve_passages(book_text, claim)\n",
    "\n",
    "# Check entailment\n",
    "entailment_checker = EntailmentChecker()\n",
    "entailment_results = entailment_checker.check_entailment(claim, retrieved_passages)\n",
    "\n",
    "print(entailment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
